L2 - Loss
Bias
Label/Unlabeled
Feature
Noise
Weights
Learning Rate
Hyperparameters tuning - dependent on your data!
Batch Size
Epoch
Oscillations in learning rates
rmse [Root Mean Square Error (]
synthetic features
Correlation Matrix - indicates when attribute raw values relate to another -+0
Generalization
	- Overfitting
	- Data Splitting
	- training set
	- test set
	- validation set
Feature engineering
	Raw data
	Feature Vector
	Vocabulary
	OOV (out of vocab bucket)
	Encoding
		One hot
		multi hot
	Sparse/Dense Representations
Scaling
NaN [not a number]
Binning
Scrubbing
Feature cross
Stochastic Gradient Descent
Generalization Curve L2 regularlization
Lambda/Regularlization rate
Logistic Regression/Sigmoid function

Classification
	Threshold
	Confusion Matrix
	Acurracy
	Precision
	Recall
Receiver Operating Chracter Curve (ROC Curve)
AUC (Area under Curve)
Prediction Bias
Calibration Layer
L1 regularlization (regularlization for sparsity)

Neural Networks
Hidden layers
Activation function
	Sigmoid
	Rectified Linear Unit Relu
Training NN
	Backpropogation failure cases
		Vanishing gradients
		Exploding gradients	
		Dead ReLU
		Dropout Regularlization
One Vs All (Sigmoid)
Softmax
	Full vs Candidate