{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huerd/GPA659-E2020/blob/howard%2Fmodel/_project/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de3vKs3GLq1k",
        "colab_type": "text"
      },
      "source": [
        "### *Resources*\n",
        "\n",
        "### Visualisations\n",
        "*   Kernel Visualizations : https://github.com/raghakot/keras-vis\n",
        "*   [Tools to design/visualize NN architecture](https://github.com/ashishpatel26/Tools-to-Design-or-Visualize-Architecture-of-Neural-Network)\n",
        "*   Image Files to Numpy Array : https://www.kaggle.com/lgmoneda/from-image-files-to-numpy-arrays\n",
        "*   MobileNetV2 Dogs/Cats implementation : https://www.kaggle.com/abdallahhassan/dogs-cats-mobilenetv2-transfere-learning\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lor2vxI9tue",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Per Runtime Setup [Authorization w/ Kaggle database and download]\n",
        "\n",
        "1.   Set your Kaggle API .JSON file to this runtime\n",
        "2.   Downloads and extract dogs-vs-cats.zip into two folders\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9NfrRKqqTI1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# updates kaggle version\n",
        "!pip install pillow==7.0.0 \n",
        "!pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "\n",
        "\n",
        "# fix https://github.com/keras-team/keras-preprocessing/issues/116 for datagen\n",
        "!pip uninstall -y keras-preprocessing\n",
        "!pip install git+https://github.com/keras-team/keras-preprocessing.git\n",
        "\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "# select your Kaggle API kaggle.json\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# make sure to create a kaggle account, get it verified (phone number and all)\n",
        "# then go accept terms here : https://www.kaggle.com/c/dogs-vs-cats\n",
        "\n",
        "# zip should be downloaded to /content/\n",
        "!kaggle competitions download -c dogs-vs-cats\n",
        "unzipMaster = zipfile.ZipFile(\"dogs-vs-cats.zip\", 'r')\n",
        "unzipMaster.extractall()\n",
        "unzipMaster.close()\n",
        "\n",
        "\n",
        "# don't expand the folders unless you want colab to crash on you\n",
        "# file format is 1.jpg, 2.jpg, etc\n",
        "unzipTest1 = zipfile.ZipFile(\"test1.zip\", 'r')\n",
        "unzipTest1.extractall()\n",
        "unzipTest1.close()\n",
        "\n",
        "# file format is cat.0.jpg, dog.2.jpg, etc\n",
        "unzipTrain1 = zipfile.ZipFile(\"train.zip\", 'r')\n",
        "unzipTrain1.extractall()\n",
        "unzipTrain1.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W_wJQ3H-jAn",
        "colab_type": "text"
      },
      "source": [
        "# Dev Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OB3uf8m3po8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "# uncomment below to use version 1.x\n",
        "#%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from keras.layers import Input, Dense, Conv2D, Conv3D, DepthwiseConv2D, SeparableConv2D, Conv3DTranspose\n",
        "from keras.layers import Flatten, MaxPool2D, AvgPool2D, GlobalAvgPool2D, UpSampling2D, BatchNormalization\n",
        "from keras.layers import Concatenate, Add, Dropout, ReLU, Lambda, Activation, LeakyReLU, PReLU\n",
        "\n",
        "from scipy import ndimage\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import numpy\n",
        "import os, sys\n",
        "import IPython.display\n",
        "import PIL.Image\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSu0MebZVd_s",
        "colab_type": "text"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXX2vwNFVdY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_WIDTH = 150\n",
        "IMAGE_LENGTH = 150\n",
        "IMAGE_SIZE = [IMAGE_WIDTH, IMAGE_LENGTH]\n",
        "IMAGE_NUMCHANNELS = 3\n",
        "\n",
        "TRAININGDATASPLIT_RATIO = 0.9\n",
        "BATCH_SIZE = 16\n",
        "SEED = 4\n",
        "\n",
        "QUICK_TRAIN = True\n",
        "EPOCH_QUICK = 3\n",
        "EPOCH_NORMAL = 50\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI1MKysYTZgD",
        "colab_type": "text"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWT6mAyfzNWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainingData_dir = \"train/\"\n",
        "testingData_dir = \"test1/\"\n",
        "\n",
        "# load data\n",
        "labeledDataset = os.listdir(trainingData_dir)\n",
        "testingDataset = os.listdir(testingData_dir)\n",
        "\n",
        "results = []\n",
        "\n",
        "# loop through our labeledDataset, one file at a time\n",
        "for eachImage in labeledDataset:\n",
        "  # recall that our labeledDataset file format is [animal].[num].jpg\n",
        "  petType = eachImage.split('.')[0]\n",
        "  if petType == 'cat':\n",
        "    results.append(\"cat\")\n",
        "  else:\n",
        "    results.append(\"dog\")\n",
        "\n",
        "# df_labeled is where all our labeled data is stored in a DataFrame\n",
        "df_labeled = pandas.DataFrame({\n",
        "    'imageName': labeledDataset,\n",
        "    'petType': results\n",
        "})\n",
        "\n",
        "## Visualizations\n",
        "# create figure size\n",
        "plt.figure(figsize=(20, 12))\n",
        "for i in range(0, 6):\n",
        "    plt.subplot(1, 6, i+1)\n",
        "    imageName = random.choice(labeledDataset)\n",
        "    image = load_img(trainingData_dir + imageName)\n",
        "    plt.title(imageName)\n",
        "    plt.imshow(image)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Total Counts from Labeled Data\")\n",
        "df_labeled['petType'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBzml4WzUaBI",
        "colab_type": "text"
      },
      "source": [
        "## Splitting training dataset into Training and Validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BQ5XcXdUZ52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split your labeled dataset into training and validation sets based on a ratio\n",
        "# if train_size is 0.3, then training is 70% of the dataset\n",
        "df_training, df_validation = train_test_split(df_labeled, train_size = TRAININGDATASPLIT_RATIO)\n",
        "\n",
        "# pandas.DataFrame.shape is a tuple\n",
        "# https://www.programiz.com/python-programming/methods/tuple\n",
        "total_dfTraining = df_training.shape[0]\n",
        "total_dfValidation = df_validation.shape[0]\n",
        "\n",
        "\n",
        "print(\"Labeled Data Allocation\")\n",
        "fmt = '{:<4} {:<2} {:<15} '\n",
        "print(fmt.format(\"Train :\", \"\", total_dfTraining))\n",
        "print(fmt.format(\"Valid :\", \"\", total_dfValidation))\n",
        "\n",
        "# ref https://github.com/IResearchAI/Tobacco_Leaves_Classification_CNN/blob/master/Tob_main1.ipynb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-nhz8jlmU4N",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing - Data Augmentation\n",
        "\n",
        "Data Augmentation is used to apply various transforms to existing labeled\n",
        "data to increase data diversity, without having to gather new data.\n",
        "\n",
        "* Keras' [ImageDataPrerocessing](https://keras.io/api/preprocessing/image/) API\n",
        "*   https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/\n",
        "*   https://colab.research.google.com/github/google/eng-edu/blob/master/ml/pc/exercises/image_classification_part2.ipynb\n",
        "\n",
        "*   [In-depth on Data Augmentation](https://medium.com/mlait/image-data-augmentation-image-processing-in-tensorflow-part-2-b77237256df0)\n",
        "\n",
        "*  [Image Classification using data generators](https://mc.ai/tutorial-image-classification-with-keras-flow_from_directory-and-generators/)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASDECBIzmURr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# playing around here I guess\n",
        "dg_training = ImageDataGenerator(\n",
        "    rotation_range = 15,\n",
        "    rescale = 1./255,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip= True,\n",
        "    fill_mode = 'nearest',\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1\n",
        ")\n",
        "\n",
        "# Returns \n",
        "# A DataFrameIterator yielding tuples of (x, y) where x is a numpy array \n",
        "# containing a batch of images with shape (batch_size, *target_size, channels) \n",
        "# and y is a numpy array of corresponding labels.\n",
        "\n",
        "train_generator = dg_training.flow_from_dataframe(\n",
        "    df_training, \n",
        "    directory = trainingData_dir, \n",
        "    x_col = 'imageName',\n",
        "    y_col = 'petType',\n",
        "    # class_mode = 'binary',\n",
        "    class_mode = 'categorical',\n",
        "    target_size = (IMAGE_WIDTH, IMAGE_LENGTH),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    seed = SEED\n",
        ")\n",
        "\n",
        "print(\"Visualized Example of Generator.\")\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 6, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# TODO have it return random images ?\n",
        "augmented_images = [train_generator[0][0][0] for i in range(6)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_K4roal1WKx",
        "colab_type": "text"
      },
      "source": [
        "Validation Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6P0YSN8dblH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# same stuff but for validation data\n",
        "# playing around here I guess\n",
        "dg_validation = ImageDataGenerator(\n",
        "    rotation_range = 15,\n",
        "    rescale = 1./255,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip= True,\n",
        "    fill_mode = 'nearest',\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1\n",
        ")\n",
        "\n",
        "# Returns \n",
        "# A DataFrameIterator yielding tuples of (x, y) where x is a numpy array \n",
        "# containing a batch of images with shape (batch_size, *target_size, channels) \n",
        "# and y is a numpy array of corresponding labels.\n",
        "\n",
        "valid_generator = dg_validation.flow_from_dataframe(\n",
        "    df_validation, \n",
        "    directory = trainingData_dir, \n",
        "    x_col = 'imageName',\n",
        "    y_col = 'petType',\n",
        "    # class_mode = 'binary',\n",
        "    class_mode = 'categorical',\n",
        "    target_size = (IMAGE_WIDTH, IMAGE_LENGTH),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    seed = SEED\n",
        ")\n",
        "\n",
        "# print(\"Visualized Example of Generator.\")\n",
        "# def plotImages(images_arr):\n",
        "#     fig, axes = plt.subplots(1, 6, figsize=(20,20))\n",
        "#     axes = axes.flatten()\n",
        "#     for img, ax in zip( images_arr, axes):\n",
        "#         ax.imshow(img)\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "\n",
        "# # TODO have it return random images\n",
        "# augmented_images = [valid_generator[0][0][0] for i in range(6)]\n",
        "# plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_VHvEZgUZtl",
        "colab_type": "text"
      },
      "source": [
        "## Test Data (TODO)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCRIhn8gUZi5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Qaz6xWISRGn",
        "colab_type": "text"
      },
      "source": [
        "# Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSxoFhx0RgUB",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "*   [MobileNet from scratch](https://github.com/IResearchAI/Tobacco_Leaves_Classification_CNN/blob/master/Tob_main2.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EqPFpFCRfo0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mobile = keras.applications.mobilenet.MobileNet()\n",
        "\n",
        "# TODO : THIS IS JUST A COPY PASTE from the link above. Might have to adjust/change\n",
        "\n",
        "def mobilenet(input_shape, n_classes):\n",
        "  \n",
        "  # TODO modify this to include pointwise ?\n",
        "  # maybe use this ? https://keras.io/api/layers/convolution_layers/separable_convolution2d/\n",
        "  def mobilenet_block(x, f, s=1):\n",
        "    x = DepthwiseConv2D(3, strides=s, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    \n",
        "    x = Conv2D(f, 1, strides=1, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    return x\n",
        "    \n",
        "    \n",
        "  input = Input(input_shape)\n",
        "\n",
        "  x = Conv2D(32, 3, strides=2, padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = ReLU()(x)\n",
        "\n",
        "  x = mobilenet_block(x, 64)\n",
        "  x = mobilenet_block(x, 128, 2)\n",
        "  x = mobilenet_block(x, 128)\n",
        "\n",
        "  x = mobilenet_block(x, 256, 2)\n",
        "  x = mobilenet_block(x, 256)\n",
        "\n",
        "  x = mobilenet_block(x, 512, 2)\n",
        "  for _ in range(5):\n",
        "    x = mobilenet_block(x, 512)\n",
        "\n",
        "  x = mobilenet_block(x, 1024, 2)\n",
        "  x = mobilenet_block(x, 1024)\n",
        "  \n",
        "  x = GlobalAvgPool2D()(x)\n",
        "  \n",
        "  output = Dense(n_classes, activation='softmax')(x)\n",
        "  \n",
        "  model = Model(input, output)\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3eJG0Fd0eTw",
        "colab_type": "text"
      },
      "source": [
        "We want to [adjust learning rate](https://machinelearningmastery.com/learning-rate-for-deep-learning-neural-networks/) when accuracy reaches certain thresholds.\n",
        "\n",
        "By using [stochastic gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) algoritm, it estimates the error gradient for the current training model and updates the weights using backpropagation.\n",
        "\n",
        "API CALLS\n",
        "\n",
        "* Keras [SGD](https://keras.io/api/optimizers/sgd/)\n",
        "* [EarlyStopping](https://machinelearningmastery.com/early-stopping-to-avoid-overtraining-neural-network-models/) : Used to reduce [overfitting](https://en.wikipedia.org/wiki/Overfitting) the training dataset and improve generalization\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4OnHQ-cbLvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Overfitting setup\n",
        "# from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "earlystop = EarlyStopping(patience=10)\n",
        "\n",
        "# learning rate change after accuracy stalls\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
        "                                            patience=2, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction]\n",
        "\n",
        "# TODO : I think we might need to actually use an optimizer\n",
        "#  ref :  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UJu578wUKsW",
        "colab_type": "text"
      },
      "source": [
        "Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-9dLxJEUKgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape=(IMAGE_WIDTH, IMAGE_LENGTH, IMAGE_NUMCHANNELS);\n",
        "n_classes = 2;\n",
        "model = mobilenet(input_shape, n_classes);\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC8gLyVbT0Xr",
        "colab_type": "text"
      },
      "source": [
        "## Model Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv-jyLLgUwL0",
        "colab_type": "text"
      },
      "source": [
        "*   Architecture Visualization : https://github.com/IResearchAI/Tobacco_Leaves_Classification_CNN/blob/master/Tob_main4.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FZ6Hre7T0GJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.utils import plot_model\n",
        "\n",
        "plot_model(model,rankdir='TB')\n",
        "\n",
        "# SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
        "# def svg_to_fixed_width_html_image(svg, width=\"100%\"):\n",
        "#     text = _html_template.format(width, base64.b64encode(svg))\n",
        "#     return HTML(text)\n",
        "\n",
        "# svg_to_fixed_width_html_image(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bThDO6Eabg_S",
        "colab_type": "text"
      },
      "source": [
        "# Training Phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcZQGXplbfBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
        "\n",
        "epochs = EPOCH_QUICK if QUICK_TRAIN else EPOCH_NORMAL\n",
        "\n",
        "# depreciated and should change to Model.fit if possible\n",
        "history = model.fit_generator(\n",
        "    train_generator, \n",
        "    epochs = epochs,\n",
        "    validation_data = valid_generator,\n",
        "    validation_steps =  total_dfValidation // BATCH_SIZE,\n",
        "    steps_per_epoch = total_dfValidation // BATCH_SIZE,\n",
        "    callbacks = callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKObpz-QT33q",
        "colab_type": "text"
      },
      "source": [
        "# Model Accuracy and Loss graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoXfmdvXT3ep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# ref  : https://github.com/IResearchAI/Tobacco_Leaves_Classification_CNN/blob/master/Tob_main2.ipynb\n",
        "\n",
        "# this is outdated. revert to model.evaluate if possible\n",
        "# loss, accuracy = model.evaluate_generator(valid_generator, \n",
        "#                                           total_dfValidation // BATCH_SIZE, \n",
        "#                                           workers=12, \n",
        "#                                           use_multiprocessing = True)\n",
        "# print(\"Test: accuracy = %f  ;  loss = %f \" % (accuracy, loss))\n",
        "\n",
        "\n",
        "\n",
        "# def plot_model_history(model_history, accuracy='acc', val_accuracy='val_acc'):\n",
        "#     fig, axs = plt.subplots(1,2,figsize=(20,20))\n",
        "#     axs[0].plot(range(1,len(model_history.history[accuracy])+1),model_history.history[accuracy])\n",
        "#     axs[0].plot(range(1,len(model_history.history[val_accuracy])+1),model_history.history[val_accuracy])\n",
        "#     axs[0].set_title('Model Accuracy')\n",
        "#     axs[0].set_ylabel('Accuracy')\n",
        "#     axs[0].set_xlabel('Epoch')\n",
        "#     axs[0].set_xticks(numpy.arange(1,len(model_history.history[accuracy])+1),len(model_history.history[accuracy])/10)\n",
        "#     axs[0].legend(['train', 'val'], loc='best')\n",
        "#     axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "#     axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "#     axs[1].set_title('Model Loss')\n",
        "#     axs[1].set_ylabel('Loss')\n",
        "#     axs[1].set_xlabel('Epoch')\n",
        "#     axs[1].set_xticks(numpy.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
        "#     axs[1].legend(['train', 'val'], loc='best')\n",
        "#     plt.show()\n",
        "    \n",
        "# plot_model_history(history)\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0LxqME3wft0",
        "colab_type": "text"
      },
      "source": [
        "# Layer Visualizations\n",
        "\n",
        "We want to visualize the model's trained filters here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hack00cQwe30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "# imageName = random.choice(testingDataset)\n",
        "# testImage = load_img(testingData_dir + imageName)\n",
        "# testImage = numpy.reshape(testImage, (150, 150))\n",
        "\n",
        "testImage = train_generator[0][0][0] \n",
        "\n",
        "# testImage = cv2.imread(testingData_dir + imageName)\n",
        "# plt.imshow(testImage)\n",
        "# use the np.resize function to solve that. I apologise for the late response. But use np.resize(img, (-1, <image shape>)\n",
        "# testImage = cv2.resize(testImage, (150,150))\n",
        "\n",
        "\n",
        "# here we get rid of that added dimension and plot the image\n",
        "def visualize_cat(model, test):\n",
        "    # Keras expects batches of images, so we have to add a dimension to trick it into being nice\n",
        "    test_batch = numpy.expand_dims(test,axis=0)\n",
        "    conv_test = model.predict(test_batch)\n",
        "    conv_test = numpy.squeeze(conv_test, axis=0)\n",
        "    plt.imshow(conv_test)\n",
        "\n",
        "test_batch = numpy.expand_dims(testImage,axis=0)\n",
        "conv_test = model.predict(test_batch)\n",
        "\n",
        "\n",
        "visualize_cat(model, testImage)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moKsupPPT8Ih",
        "colab_type": "text"
      },
      "source": [
        "# Confusion Matrix\n",
        "\n",
        "A [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) is a table that is often used to describe the performance of a classification model (or “classifier”) on a set of test data for which the true values are known. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw_qcFreT7_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}